# ========================================
# PANGEIA AI CONFIGURATION
# ========================================
# Configure o provedor de IA para o agente conversacional
# Se não configurado, o Pangeia usará apenas regex patterns

# Provider: openai, anthropic, groq, ou local
# PANGEIA_AI_PROVIDER=openai

# API Key do provider escolhido
# PANGEIA_AI_API_KEY=sk-...

# Modelo a ser usado (opcional, cada provider tem seu padrão)
# OpenAI: gpt-4o-mini, gpt-4o, gpt-3.5-turbo
# Anthropic: claude-3-5-sonnet-20241022, claude-3-haiku-20240307
# Groq: llama-3.1-70b-versatile, mixtral-8x7b-32768
# Local: llama3, mistral, etc (depende do servidor local)
# PANGEIA_AI_MODEL=gpt-4o-mini

# Temperatura (0.0 a 1.0) - controla criatividade
# PANGEIA_AI_TEMPERATURE=0.7

# Máximo de tokens na resposta
# PANGEIA_AI_MAX_TOKENS=500

# ========================================
# EXEMPLOS DE CONFIGURAÇÃO
# ========================================

# OpenAI (GPT-4)
# PANGEIA_AI_PROVIDER=openai
# PANGEIA_AI_API_KEY=sk-proj-...
# PANGEIA_AI_MODEL=gpt-4o-mini

# Anthropic Claude
# PANGEIA_AI_PROVIDER=anthropic
# PANGEIA_AI_API_KEY=sk-ant-...
# PANGEIA_AI_MODEL=claude-3-5-sonnet-20241022

# Groq (LLaMA 3.1 - RÁPIDO E GRATUITO!)
# PANGEIA_AI_PROVIDER=groq
# PANGEIA_AI_API_KEY=gsk_...
# PANGEIA_AI_MODEL=llama-3.1-70b-versatile

# Ollama Local (localhost)
# PANGEIA_AI_PROVIDER=local
# PANGEIA_AI_API_KEY=http://localhost:11434/api/chat
# PANGEIA_AI_MODEL=llama3
