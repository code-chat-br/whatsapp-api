/**
 * â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
 * â”‚ @author Pangeia Team                                                         â”‚
 * â”‚ @filename ai.service.ts                                                      â”‚
 * â”‚ Developed by: Pangeia Task Management System                                 â”‚
 * â”‚ Creation date: Oct 24, 2025                                                  â”‚
 * â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
 * â”‚ @copyright Â© Pangeia 2025. All rights reserved.                              â”‚
 * â”‚ ServiÃ§o de IA Conversacional para o Agente Pangeia                           â”‚
 * â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
 */

import axios from 'axios';

export interface AIConfig {
  provider: 'openai' | 'anthropic' | 'groq' | 'local';
  apiKey: string;
  model?: string;
  temperature?: number;
  maxTokens?: number;
}

export interface Message {
  role: 'system' | 'user' | 'assistant';
  content: string;
}

export interface IntentResponse {
  intent: string;
  entities: Record<string, any>;
  confidence: number;
  explanation?: string;
  suggestedResponse?: string;
}

export class AIService {
  private config: AIConfig;

  constructor(config: AIConfig) {
    this.config = {
      temperature: 0.7,
      maxTokens: 500,
      ...config,
    };
  }

  /**
   * Identifica a intenÃ§Ã£o do usuÃ¡rio usando IA
   */
  async identifyIntent(userMessage: string, context?: {
    userName: string;
    isLeader: boolean;
    recentTasks?: string[];
  }): Promise<IntentResponse> {
    const systemPrompt = this.buildIntentSystemPrompt();
    const userPrompt = this.buildIntentUserPrompt(userMessage, context);

    const messages: Message[] = [
      { role: 'system', content: systemPrompt },
      { role: 'user', content: userPrompt },
    ];

    try {
      const response = await this.chat(messages);
      return this.parseIntentResponse(response);
    } catch (error) {
      console.error('Erro ao identificar intenÃ§Ã£o com IA:', error);
      // Fallback para resposta padrÃ£o
      return {
        intent: 'unknown',
        entities: {},
        confidence: 0,
        explanation: 'NÃ£o consegui entender sua mensagem. Tente novamente.',
      };
    }
  }

  /**
   * Gera uma resposta conversacional usando IA
   */
  async generateResponse(
    intent: string,
    entities: Record<string, any>,
    taskResult: any,
    context?: {
      userName: string;
      isLeader: boolean;
    }
  ): Promise<string> {
    const systemPrompt = this.buildResponseSystemPrompt();
    const userPrompt = this.buildResponseUserPrompt(intent, entities, taskResult, context);

    const messages: Message[] = [
      { role: 'system', content: systemPrompt },
      { role: 'user', content: userPrompt },
    ];

    try {
      return await this.chat(messages);
    } catch (error) {
      console.error('Erro ao gerar resposta com IA:', error);
      return 'AÃ§Ã£o realizada com sucesso!';
    }
  }

  /**
   * Chat genÃ©rico com IA
   */
  private async chat(messages: Message[]): Promise<string> {
    switch (this.config.provider) {
      case 'openai':
        return await this.chatOpenAI(messages);
      case 'anthropic':
        return await this.chatAnthropic(messages);
      case 'groq':
        return await this.chatGroq(messages);
      case 'local':
        return await this.chatLocal(messages);
      default:
        throw new Error(`Provider nÃ£o suportado: ${this.config.provider}`);
    }
  }

  /**
   * Chat com OpenAI
   */
  private async chatOpenAI(messages: Message[]): Promise<string> {
    const response = await axios.post(
      'https://api.openai.com/v1/chat/completions',
      {
        model: this.config.model || 'gpt-4o-mini',
        messages,
        temperature: this.config.temperature,
        max_tokens: this.config.maxTokens,
      },
      {
        headers: {
          'Authorization': `Bearer ${this.config.apiKey}`,
          'Content-Type': 'application/json',
        },
      }
    );

    return response.data.choices[0].message.content.trim();
  }

  /**
   * Chat com Anthropic Claude
   */
  private async chatAnthropic(messages: Message[]): Promise<string> {
    // Separa system message
    const systemMessage = messages.find(m => m.role === 'system')?.content || '';
    const conversationMessages = messages.filter(m => m.role !== 'system');

    const response = await axios.post(
      'https://api.anthropic.com/v1/messages',
      {
        model: this.config.model || 'claude-3-5-sonnet-20241022',
        max_tokens: this.config.maxTokens,
        temperature: this.config.temperature,
        system: systemMessage,
        messages: conversationMessages.map(m => ({
          role: m.role === 'assistant' ? 'assistant' : 'user',
          content: m.content,
        })),
      },
      {
        headers: {
          'x-api-key': this.config.apiKey,
          'anthropic-version': '2023-06-01',
          'Content-Type': 'application/json',
        },
      }
    );

    return response.data.content[0].text.trim();
  }

  /**
   * Chat com Groq (LLaMA, Mixtral, etc)
   */
  private async chatGroq(messages: Message[]): Promise<string> {
    const response = await axios.post(
      'https://api.groq.com/openai/v1/chat/completions',
      {
        model: this.config.model || 'llama-3.1-70b-versatile',
        messages,
        temperature: this.config.temperature,
        max_tokens: this.config.maxTokens,
      },
      {
        headers: {
          'Authorization': `Bearer ${this.config.apiKey}`,
          'Content-Type': 'application/json',
        },
      }
    );

    return response.data.choices[0].message.content.trim();
  }

  /**
   * Chat com modelo local (Ollama, LM Studio, etc)
   */
  private async chatLocal(messages: Message[]): Promise<string> {
    const response = await axios.post(
      this.config.apiKey, // URL do servidor local
      {
        model: this.config.model || 'llama3',
        messages,
        stream: false,
      },
      {
        headers: {
          'Content-Type': 'application/json',
        },
      }
    );

    return response.data.message.content.trim();
  }

  /**
   * ConstrÃ³i o prompt de sistema para identificaÃ§Ã£o de intenÃ§Ã£o
   */
  private buildIntentSystemPrompt(): string {
    return `VocÃª Ã© um assistente especializado em identificar intenÃ§Ãµes de usuÃ¡rios em um sistema de gestÃ£o de tarefas chamado Pangeia.

Seu trabalho Ã© analisar mensagens de usuÃ¡rios e identificar:
1. A INTENÃ‡ÃƒO principal (intent)
2. As ENTIDADES relevantes (entities)
3. O nÃ­vel de CONFIANÃ‡A (0 a 1)

INTENÃ‡Ã•ES DISPONÃVEIS:
- create_task: Criar uma nova tarefa
- list_tasks: Listar tarefas (com filtros opcionais: pendentes, em andamento, concluÃ­das, todas)
- my_tasks: Ver tarefas do prÃ³prio usuÃ¡rio
- task_details: Ver detalhes de uma tarefa especÃ­fica
- start_task: Iniciar uma tarefa
- complete_task: Marcar tarefa como concluÃ­da
- cancel_task: Cancelar uma tarefa
- assign_task: Atribuir tarefa a alguÃ©m
- comment_task: Adicionar comentÃ¡rio em tarefa
- set_priority: Definir prioridade (baixa, mÃ©dia, alta, urgente)
- set_due_date: Definir prazo
- list_members: Listar membros da equipe
- list_leaders: Listar lÃ­deres
- team_report: Ver estatÃ­sticas da equipe
- overdue_tasks: Ver tarefas atrasadas
- help: Pedir ajuda
- greeting: Cumprimentar
- unknown: IntenÃ§Ã£o nÃ£o identificada

ENTIDADES POSSÃVEIS:
- taskId: nÃºmero da tarefa (ex: #5, tarefa 3)
- title: tÃ­tulo da nova tarefa
- filter: filtro para listagem (pendentes, em andamento, concluÃ­das, todas)
- assignee: nome da pessoa
- comment: texto do comentÃ¡rio
- priority: prioridade (baixa, mÃ©dia, alta, urgente)
- dueDate: data de prazo
- description: descriÃ§Ã£o adicional

RESPONDA SEMPRE EM JSON com esta estrutura:
{
  "intent": "nome_da_intencao",
  "entities": { "chave": "valor" },
  "confidence": 0.95,
  "explanation": "Breve explicaÃ§Ã£o do que vocÃª entendeu"
}

Seja flexÃ­vel com a linguagem natural do usuÃ¡rio. Exemplos:
- "preciso criar uma tarefa pra revisar o cÃ³digo" â†’ create_task
- "quais sÃ£o minhas tarefas?" â†’ my_tasks
- "finaliza a tarefa 5" â†’ complete_task (taskId: 5)
- "o que tem pra fazer?" â†’ list_tasks (filter: "pendentes")`;
  }

  /**
   * ConstrÃ³i o prompt de usuÃ¡rio para identificaÃ§Ã£o de intenÃ§Ã£o
   */
  private buildIntentUserPrompt(
    userMessage: string,
    context?: {
      userName: string;
      isLeader: boolean;
      recentTasks?: string[];
    }
  ): string {
    let prompt = `Analise esta mensagem e identifique a intenÃ§Ã£o:\n\n"${userMessage}"`;

    if (context) {
      prompt += `\n\nCONTEXTO:`;
      prompt += `\n- UsuÃ¡rio: ${context.userName}`;
      prompt += `\n- Ã‰ lÃ­der: ${context.isLeader ? 'Sim' : 'NÃ£o'}`;

      if (context.recentTasks && context.recentTasks.length > 0) {
        prompt += `\n- Tarefas recentes: ${context.recentTasks.join(', ')}`;
      }
    }

    prompt += `\n\nResponda APENAS com o JSON, sem texto adicional.`;

    return prompt;
  }

  /**
   * ConstrÃ³i o prompt de sistema para geraÃ§Ã£o de resposta
   */
  private buildResponseSystemPrompt(): string {
    return `VocÃª Ã© o Pangeia, um assistente amigÃ¡vel e eficiente de gestÃ£o de tarefas via WhatsApp.

PERSONALIDADE:
- Profissional mas amigÃ¡vel
- Conciso e direto
- Usa emojis apropriadamente (mas sem exagero)
- Encoraja e motiva a equipe
- Oferece ajuda proativa quando apropriado

REGRAS DE FORMATAÃ‡ÃƒO:
- Use *negrito* para destacar informaÃ§Ãµes importantes
- Use emojis contextuais (âœ… sucesso, âš ï¸ atenÃ§Ã£o, ğŸ“‹ tarefas, etc)
- Seja breve - mÃ¡ximo 200 caracteres para confirmaÃ§Ãµes simples
- Para listas, use formato claro e organizado
- Sempre ofereÃ§a prÃ³ximos passos quando relevante

EXEMPLOS DE BOM TOM:
- "âœ… Tarefa criada! Quer que eu atribua a alguÃ©m?"
- "ğŸ“‹ VocÃª tem 3 tarefas pendentes. Bora comeÃ§ar pela mais urgente?"
- "ğŸ‰ ParabÃ©ns! Mais uma tarefa concluÃ­da!"
- "âš ï¸ Opa! Essa tarefa jÃ¡ estÃ¡ atrasada. Precisa de ajuda?"`;
  }

  /**
   * ConstrÃ³i o prompt de usuÃ¡rio para geraÃ§Ã£o de resposta
   */
  private buildResponseUserPrompt(
    intent: string,
    entities: Record<string, any>,
    taskResult: any,
    context?: {
      userName: string;
      isLeader: boolean;
    }
  ): string {
    let prompt = `Gere uma resposta natural para o usuÃ¡rio baseada nesta aÃ§Ã£o:\n\n`;
    prompt += `INTENÃ‡ÃƒO: ${intent}\n`;
    prompt += `ENTIDADES: ${JSON.stringify(entities, null, 2)}\n`;
    prompt += `RESULTADO: ${JSON.stringify(taskResult, null, 2)}\n`;

    if (context) {
      prompt += `\nUSUÃRIO: ${context.userName}`;
      prompt += `\nÃ‰ LÃDER: ${context.isLeader ? 'Sim' : 'NÃ£o'}`;
    }

    prompt += `\n\nGere uma resposta clara, amigÃ¡vel e Ãºtil. Inclua emojis apropriados.`;
    prompt += `\nResponda APENAS com o texto da mensagem, sem formataÃ§Ã£o JSON.`;

    return prompt;
  }

  /**
   * Faz parse da resposta de intenÃ§Ã£o
   */
  private parseIntentResponse(response: string): IntentResponse {
    try {
      // Remove possÃ­veis markdown code blocks
      let cleaned = response.trim();
      cleaned = cleaned.replace(/^```json\s*/i, '');
      cleaned = cleaned.replace(/^```\s*/i, '');
      cleaned = cleaned.replace(/\s*```$/i, '');
      cleaned = cleaned.trim();

      const parsed = JSON.parse(cleaned);

      return {
        intent: parsed.intent || 'unknown',
        entities: parsed.entities || {},
        confidence: parsed.confidence || 0.5,
        explanation: parsed.explanation,
        suggestedResponse: parsed.suggestedResponse,
      };
    } catch (error) {
      console.error('Erro ao fazer parse da resposta de IA:', error);
      console.error('Resposta recebida:', response);
      return {
        intent: 'unknown',
        entities: {},
        confidence: 0,
        explanation: 'Erro ao processar resposta',
      };
    }
  }

  /**
   * Valida se a configuraÃ§Ã£o estÃ¡ correta
   */
  static validateConfig(config: AIConfig): boolean {
    if (!config.provider) {
      throw new Error('Provider de IA nÃ£o configurado');
    }

    if (!config.apiKey) {
      throw new Error('API Key nÃ£o configurada');
    }

    return true;
  }

  /**
   * Testa a conexÃ£o com a IA
   */
  async testConnection(): Promise<boolean> {
    try {
      const response = await this.chat([
        { role: 'user', content: 'Responda apenas "OK" se vocÃª estiver funcionando.' }
      ]);

      return response.toLowerCase().includes('ok');
    } catch (error) {
      console.error('Erro ao testar conexÃ£o com IA:', error);
      return false;
    }
  }
}
